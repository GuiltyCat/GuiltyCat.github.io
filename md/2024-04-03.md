音を作る言語を作りたい
====

2024/04/03

人工音声や音楽を作る言語を作りたい．

巷では深層学習を使って，人の声をベースに自然な発音をさせたり，
あるいは，ボイスチェンジャーのように声を別の人の声に変換したりと様々な方法がある．

でも，私が作りたいのはもっと人工的で理論的な例えばフォルマントを活用した人工音声作成だ．
なぜならコテコテにチューニングできるからだ．
その上で伸びやかな声で色々としゃべらせたり歌わせたりしてみたい．

その一方で，簡単な作曲とかもしてみたいと考えている．
つまり，作曲で音を作りつつそれを人工音声で歌ってみるとかできたらいいなと．

ここでいくつかやりたいことが見えてくる．
まずは作曲をしたいので，基本的な楽譜を書けるようにする必要がある．

さらに，楽器を割り当てたり，あるいはビブラートとか変調とか，音の大きさを変化させたりだとか，
そうした装飾的なことを後から自在に編集できるようにしたい．

すると，こんなことがしたい．


1. 楽譜を書ける
2. 楽器の音セットを作れる
3. 音量やビブラートなどの修飾を後から追加できる

まあ，ありもののソフトを組み合わせたらできるんだろうけれども，
ここはちょっとオリジナルで作ってみたくなってしまった．

色々とアイディアはあるが，記述方法が面倒臭すぎたり，
理論的にはきれいだけどちょっと実用したくはないだったりで，中々落し所が見つかっていない．

というわけで，せっかくなのでこの記事を使ってそのあたりの考えをまとめていければなと思っている．

まずは最初ということで，これぐらいにしておく．

2024/04/04

音を作る要素はいくつかある．
フーリエ変換から分かる通り，理論上は単純なsin波の組み合わせで全ての音を作ることができる．
しかし，実際にはそんな面倒な手法で音楽を作ったりはしない．

音楽の3要素として上げられるのが以下である．

- リズム
- メロディ
- ハーモニー

ここで問題になるのが，この3つの要素がひっついて音楽になっているため，
この3つを同時に記述する必要があるということだ．

例えば単線律であればその音の高さと長さを順番に書いていくだけでよい．
しかし，ハーモニになったり，あるいはバッハのように複数のメロディが同時進行したり，
さらにはそれらが交差した場合にはどう記述するかが難しい．

なぜなら，単旋律であれば一つの音を記述すれば，基本的にはその後ろにしか音が現れることがない．
つまり記述上前から読んでいって時間を遡ることがない．

したがって，ハーモニーを構成する場合，あるメロディに紐付くものは同時にならすなどブロック構造を持たせる．
そして，異なるメロディを裏で流したい場合には時間を巻き戻して記述をすることが必要になる．
そうしないと，複数のメロディをハーモニーの形で記述するとごちゃごちゃしすぎて何を書いているのか分からなくなるからだ．

しかし，このような記述法はある音楽を表現しようとした時に複数の表現方法があることを意味する．
こういうことを許すとコーディング規約みたいな面倒な流派を作り出してしまうため避けたい．(とはいっても妥協するだろうが)


さて，ここまでは音楽を作るのに必要な要素を説明した．
ここからは，楽器の音を作ることにフォーカスする．

単純に言えばシンセサイザーの真似をすればいいっちゃいいのかもしれない．

楽器の音を作りたい場合，ある音の高さ，長さをした時にどのような形状の波形を生成するかを決めることに他ならない．
更に，楽器に特定の特性があってそれをパラメータで指定したい場合には，上記パラメータに加えてその特性パラメータも含められるようにする必要がある．

こういうことをしたい場合，プログラマー的には横着をしたくなる．
つまり音の高さパラメータfと長さlに対して，数式的に楽器を記述する方法だ．当面はこれを採用することになるだろう．
ただし，実際の楽器の場合特定の音だと共鳴が強まるなど，単にfとlを連結したような単純な音にはならない．
こういうマニアックなこともできるようにはしておきたい．

この場合fやlを含めた複数のパラメータを取得し，ある時刻tにおける波形の振幅を出力する関数を定義できること．
さらに，その関数にtを入力し実際の波形配列を取得するこの2段階に分かれる．

この時シンセイサイザーのようにエンウ゛ェロープを持ってこないと，音と音の繋ぎで信号が連続的でなくなるのでブチッとした強烈な音が発生する．
イメージとしてはパルス波を流し込むようなもので，周波数領域の広い範囲にバツッとパワーが入ってしまう．


次に，音楽を修飾する要素についても説明する．

上記で楽器の要素で実際の波形配列を生成すると書いたが，実際のユースケースを考えると，
楽器の音を入れ換えるのではなくその楽器の音のままでビブラートを入れたり，あるいは音量を連続的に変化させたりといった処理を入れたなくなる．

単純に音量を変化させるだけでよければ，振幅を変化させるだけでよいので，ある関数を掛ければよい．
しかし，周波数領域でビブラートを掛けたいとなるとちょっと面倒なことになる．

一応取得できた配列の間を補完すれば，擬似的に高解像度な信号になるため，その信号をベースにtを揺らすことで擬似的にfを揺らすことができる．

ただより厳密にそして美しく実装するのであれば，上記楽器の音を生成する場合に最初からfをf(t)のように時間に依存して変化するfにしておく方がよい．

この場合，コンパイルする時に初めて楽器の音の詳細が決まるという，中々アクロバティックかつダイナミックなことになる．

単純な音でよければいいが，どんどん音を重ねたりした場合にこれで成立するのかがちょっと心配になる．

とりあえず今日はここまで．
次からは，実際の楽器の記述法，音楽の記述法について触れていきたい．
まだまだ理想のあり方だったり一般論を述べているだけで，中々具体的な実装や仕様にまで踏み込めていないが，
さらに言えばずっと前からメモや頭の中には考えていたことを後追いでチョビチョビ出しているだけだが，
こうやってとりとめもなく書き連ねていくと進んでいる気がしてくる．



