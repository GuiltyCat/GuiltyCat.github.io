特定のページ経由でしか見れないサイトの攻略方法
=======================

大層な出だしだが，Web業界では当然のことかもしれない．

例えばあるサイトにある画像が欲しいとする．
画像が表示されているのであれば`<img>`タグがあるので，そこのsrcかそこらのパスから，
本体の場所を持ってきて`wget`とか`curl`とかすればよい．

たまに相対パスになっていることがあるので，
その場合は元のURLと貼り合わせれば簡単に推測できる．


問題
--------

この`src`とかで指定されているファイルが直接ダウンロードできないことがある．

具体的にはsrcのURLをコピペして開こうとすると，
Error 1020とか出て，Access deniedと表示されたりすることがある．

元のURLからはきちんと表示されているのになんで?


原因
---

表示はされているから，IPがブロックされたわけではなさそう．
ただ，直接アクセスが禁止されている．

となると，HTTPリクエストの中に何かしらの情報が載っていて，それで直接来たのかどうかを判定しているんじゃないかと考えた．
つまり，`img src`をリクエストする時にはそのヘッダに何か追加情報が書き込まれていて，
それがあるかないかで判定しているんじゃなかろうかと．

というわけで，そのヘッダを見てみてみました．

すると`referer`という怪しげな名前に元のURLのアドレスが書かれているではありませんか．

このrefererというのは，どういう経路でアクセスしてきたのかを示す情報らしい．
おお，予想通り．

つまり，refererの中身が想定されていた場所と一致しているかどうかを見て弾いている可能性がある．


解決
---

というわけで，以下のようにリクエストヘッダにrefererを追記することで無事にダウンロードできるようになりました．

```
wget --referer=<URL> ...
```

最後に
------

HTTPにrefererみたいな機能があるとは露も知らず．

もっとCookieとか活用して裏でゴニョゴニョしていると思っていて，面倒だと考えていたが，
こんな簡単な方法を使っていたとは驚きだった．
